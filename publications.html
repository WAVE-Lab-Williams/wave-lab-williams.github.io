<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WAVElab - Publications</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="icon" type="image/svg+xml" href="img/favicon.svg">
    <link rel="icon" type="image/png" href="img/favicon.png">
</head>
<body>
    <div id="header-container"></div>
    <div id="nav-container"></div>

    <main class="container">
        <div class="fade-in">
            <div class="section-header">Manuscripts</div>

            <div class="publication">
                <div class="publication-content">
                    <p><strong>Bi, W., Shah, A. D., Wong, K. W., Scholl, B. J., & Yildirim, I.</strong> (in press). Computational models reveal that intuitive physics underlies visual processing of soft objects. <i>Nature Communications.</i></p>
                    <button class="show-abstract-btn" onclick="toggleAbstract(this)">Show abstract</button>
                    <div class="abstract" style="display: none;">
                        <p>Computational explorations of human cognition have been especially successful when applied to visual perception. Existing models have primarily focused on rigid objects, emphasizing shape-preserving invariance to changes in viewpoint, lighting, object size, and scene context. Yet many objects in our everyday environments, such as cloths, are soft. This poses both quantitatively greater and qualitatively different challenges for models of perception, due to soft objects' dynamic and high-dimensional internal structure — as in the changing folds and wrinkles of a cloth waving in the wind. Soft object perception is also correspondingly rich, involving novel properties such as stiffness. Here we explore the ability of different kinds of computational models to capture visual perception of the physical properties of cloths (e.g., their degrees of stiffness) undergoing different naturalistic transformations (e.g., falling vs. waving in the wind). Across visual matching tasks, both the successes and failures of human performance are well explained by Woven — a novel model that incorporates physics-based simulations to infer probabilistic representations of cloths. Woven outperforms powerful, performance-equated alternatives, including its ablations and a deep neural network, and suggests that humanlike machine vision may also require representations that transcend image statistics, and involve intuitive physics.</p>
                    </div>
                </div>
            </div>

            <div class="publication">
                <div class="publication-content">
                    <p><strong>Ongchoco, J. D. K., Wong, K. W., & Scholl, B. J.</strong> (submitted). The "unfinishedness" of dynamic events is spontaneously extracted in visual perception: A new 'Visual Zeigarnik Effect'.</p>
                    <button class="show-abstract-btn" onclick="toggleAbstract(this)">Show abstract</button>
                    <div class="abstract" style="display: none;">
                        <p>The events that occupy our thoughts in an especially persistent way are often those that are unfinished — half-written papers, unfolded laundry, and items not yet crossed off from to-do lists. And this factor has also been emphasized in work within higher-level cognition, as in the "Zeigarnik effect": when people carry out various tasks, but some are never finished due to extrinsic interruptions, memory tends to be better for those tasks that were unfinished. But just how foundational is this sort of "unfinishedness" in mental life? Might such unfinishedness be spontaneously extracted and prioritized even in lower-level visual processing? To explore this, we had observers watch animations in which a dot moved through a maze, starting at one disc (the 'startpoint') and moving toward another disc (the 'endpoint'). We tested the fidelity of visual memory by having probes (colored squares) appear briefly along the dot's path; after the dot finished moving, observers simply had to indicate where the probes had appeared. On 'Completed' trials, the motion ended when the dot reached the endpoint, but on 'Unfinished' trials, the motion ended shortly before the dot reached the endpoint. Although this manipulation was entirely task-irrelevant, it nevertheless had a powerful influence on visual memory: observers placed probes much closer to their correct locations on Unfinished trials. This same pattern held across several different experiments, even while carefully controlling for various lower-level properties of the displays (such as the speed and duration of the dot's motion). And the effect also generalized across different types of displays (e.g. also replicating when the moving dot left a visible trace). This new type of Visual Zeigarnik Effect suggests that the unfinishedness of events is not just a matter of higher-level thought and motivation, but can also be extracted as a part of visual perception itself.</p>
                    </div>
                </div>
            </div>

            <div class="publication">
                <div class="publication-content">
                    <p><strong>Wong, K. W., Shah, A. D. & Scholl, B. J.</strong> (in prep). Unconscious intuitive physics: Prioritized breakthrough into visual awareness for physically unstable block towers.</p>
                    <button class="show-abstract-btn" onclick="toggleAbstract(this)">Show abstract</button>
                    <div class="abstract" style="display: none;">
                        <p>A central goal of perception and cognition is to predict how events in our local environments are likely to unfold: what is about to happen? And of course some of the most reliable ways of answering this question involve considering the regularities of physics. Accordingly, a great deal of recent research throughout cognitive science has explored the nature of 'intuitive physics'. The vast majority of this work, however, has involved higher-level reasoning, rather than seeing itself — as when people are asked to deliberate about how objects might move, in response to explicit questions ("Will it fall?"). Here, in contrast, we ask whether the apprehension of certain physical properties of scenes might also occur *unconsciously*, during simple passive viewing. Moreover, we ask whether certain physical regularities are not just processed, but also visually *prioritized* — as when a tower is about to fall. Observers viewed block towers — some stable, some unstable — defined in terms of whether they would collapse as a result of external physical forces (such as gravity) alone. We used continuous flash suppression (CFS) to render the towers initially invisible: observers viewed them monocularly through a mirror haploscope, while a dynamic Mondrian mask was presented to their other eye. We then measured how long towers took to break through this interocular suppression, as observers indicated when they became visually aware of anything other than the mask. The results were clear and striking: unstable towers broke into visual awareness faster than stable towers. And this held even while controlling for other visual properties — e.g. while contrasting pairs of stable vs. unstable towers sharing the same convex hull, and differing only in the horizontal placement of a single block. This work shows how physical instability is both detected and prioritized, not only during overt deliberation, but also in unconscious visual processing.</p>
                    </div>
                </div>
            </div>

            <div class="section-header">Publications</div>
            <div class="publication">
                <div class="publication-content">
                    <p><strong>Wong, K. W., & Scholl, B. J.</strong> (2024). Spontaneous path tracing in task-irrelevant mazes: Spatial affordances trigger dynamic visual routines. <em>Journal of Experimental Psychology: General</em>. <em>153</em>(9), 2230-2238.</p>
                    <p><a href="https://doi.org/10.1037/xge0001618" target="_blank">DOI</a> <a href="/public/wong-scholl-JEPG.pdf" target="_blank">PDF</a></p>
                </div>
            </div>

            <div class="publication">
                <div class="publication-content">
                    <p><strong>Ongchoco, J. D. K., Wong, K. W., & Scholl, B. J.</strong> (2024). What's next?: Time is subjectively dilated not only for 'oddball' events, but also for events immediately after oddballs. <em>Attention, Perception, & Psychophysics</em>, <em>86</em>(1), 16-21.</p>
                    <p><a href="https://doi.org/10.3758/s13414-023-02800-7" target="_blank">DOI</a> <a href="/public/ongchoco-etal-2024-APP.pdf" target="_blank">PDF</a></p>
                </div>
            </div>

            <div class="publication">
                <div class="publication-content">
                    <p><strong>Wong, K. W., Bi, W., Soltani, A. A., Yildirim, I., & Scholl, B. J.</strong> (2023). Seeing soft materials draped over objects: A case study of intuitive physics in perception, attention, and memory. <em>Psychological Science</em>, <em>34</em>(1), 111-119.</p>
                    <p><a href="https://doi.org/10.1177/09567976221109194" target="_blank">DOI</a> <a href="/public/wong-etal-2023-PsychSci.pdf" target="_blank">PDF</a></p>
                </div>
            </div>

            <div class="publication">
                <div class="publication-content">
                    <p><strong>Wong, K., Wadee, F., Ellenblum, G., & McCloskey, M.</strong> (2018). The devil's in the g-tails: Deficient letter-shape knowledge and awareness despite massive visual experience. <em>Journal of Experimental Psychology: Human Perception and Performance</em>, <em>44</em>(9), 1324-1335.</p>
                    <p><a href="https://doi.org/10.1037/xhp0000532" target="_blank">DOI</a> <a href="/public/wong-etal-2018-JEPHPP.pdf" target="_blank">PDF</a> <a href="https://hub.jhu.edu/magazine/2018/summer/elusive-looptail-g/" target="_blank">Video Summary</a></p>
                </div>
            </div>

        </div>
    </main>

    <div id="footer-container"></div>

    <script src="script.js"></script>
    <script>
        function toggleAbstract(button) {
            const abstract = button.nextElementSibling;
            if (abstract.style.display === 'none' || abstract.style.display === '') {
                abstract.style.display = 'block';
                button.textContent = 'Hide abstract';
            } else {
                abstract.style.display = 'none';
                button.textContent = 'Show abstract';
            }
        }
    </script>
</body>
</html>